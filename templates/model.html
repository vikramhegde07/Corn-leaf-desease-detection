<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deep learning models</title>
</head>

<body>
    {% include 'navbar.html' %}

    <div class="container p-4 mt-5">
        <div class="container bg-success-subtle p-3 mt-4 rounded">
            <h1 class="text-center"> Model: EfficientNet</h1>
            <hr>
            <p class="fs-5">
                The MBConv layer is a fundamental building block of the EfficientNet architecture. It is inspired by the
                inverted residual blocks from MobileNetV2 but with some modifications. The MBConv layer starts with a
                depth-wise convolution, followed by a point-wise convolution (1x1 convolution) that expands the number
                of channels, and finally, another 1x1 convolution that reduces the channels back to the original number.
                This bottleneck design allows the model to learn efficiently while maintaining a high degree of
                representational power. In addition to MBConv layers, EfficientNet incorporates the SE block, which
                helps the model learn to focus on essential features and suppress less relevant ones. The SE block uses
                global average pooling to reduce the spatial dimensions of the feature map to a single channel, followed
                by two fully connected layers. These layers allow the model to learn channel-wise feature dependencies
                and create attention weights that are multiplied with the original feature map, emphasizing important
                information.
            </p>
        </div>
        <div class="container bg-success-subtle p-3 mt-4 rounded">
            <h1 class="text-center"> Model: VGG19</h1>
            <hr>
            <p class="fs-5">
                VGG19 is a deep convolutional neural network (CNN) architecture that has made significant contributions
                to
                the field of computer vision. Developed by researchers at Oxford University, VGG19 is characterized by
                its
                use of multiple convolutional layers with very small (3x3) receptive fields. This design choice allows
                the
                network to capture fine-grained visual features and learn complex patterns in images. VGG19 achieved
                state-of-the-art performance on the ImageNet classification benchmark when it was introduced,
                demonstrating
                its effectiveness in object recognition and classification tasks. The architecture's simplicity and
                effectiveness have made it a popular choice for transfer learning, where pre-trained VGG19 models can be
                fine-tuned for various downstream tasks, such as image segmentation, object detection, and style
                transfer.
            </p>
        </div>
        <div class="container bg-success-subtle p-3 mt-4 rounded">
            <h1 class="text-center"> Model: CNN</h1>
            <hr>
            <p class="fs-5">
                CNNs are a type of deep learning architecture specifically designed for processing and analyzing visual
                data. They are inspired by the biological processes of the human visual cortex, where neurons are
                organized
                in layers to detect and recognize patterns in images. CNNs are composed
                of multiple layers, including convolutional layers, pooling layers, and fully connected layers.
                Convolutional layers apply filters to the input image, extracting features such as edges, corners, and
                textures. Pooling layers reduce the dimensionality of the feature maps while preserving important
                information. Finally, fully connected layers combine the extracted features to classify or predict the
                content of the image. CNNs have revolutionized the field of computer vision, enabling breakthroughs in
                tasks
                such as image classification, object detection, image segmentation, and natural language processing.
                Their
                ability to learn complex visual representations from large datasets has made them indispensable tools
                for a
                wide range of applications, from self-driving cars to medical image analysis.
            </p>
        </div>
    </div>

</body>

</html>